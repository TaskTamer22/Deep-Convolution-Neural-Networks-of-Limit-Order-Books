{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Installing necessary packages for the proper functioning of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (2.4.3)\n",
      "Requirement already satisfied: pyyaml in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from Keras) (5.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from Keras) (1.17.2)\n",
      "Requirement already satisfied: h5py in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from Keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from Keras) (1.4.1)\n",
      "Requirement already satisfied: six in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from h5py->Keras) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Keras #installing Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (20.2.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip #Upgrading pip \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.33.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (0.33.6)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (41.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.23.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (0.23)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: more-itertools in /Users/oindrilamukherjee/opt/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (7.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow #installing Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary packages for the functioning \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying the datapath from the source\n",
    "train_data_file = '/kaggle/input/fi2010/FI2010/FI2010_train.csv'\n",
    "test_data_file = '/kaggle/input/fi2010/FI2010/FI2010_test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Just in case if this code is processed in google colab the way to upload the datset is\n",
    "*loading dataset\n",
    "from google.colab import files\n",
    "uploaded = files.upload()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0         1         2         3         4         5         6  \\\n",
      "0       0.318116 -0.564619  0.313539 -0.551889  0.319726 -0.731228  0.312891   \n",
      "1       0.318116 -0.662079  0.313539 -0.551889  0.320706 -0.751891  0.312891   \n",
      "2       0.317136 -0.723163  0.313539 -0.551889  0.316787 -0.731228  0.312891   \n",
      "3       0.317136 -0.585895  0.313539 -0.551889  0.318747 -0.307628  0.312891   \n",
      "4       0.317136 -0.585895  0.313539 -0.551889  0.318747 -0.307628  0.312891   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "362395  1.328480 -0.608544  1.329517 -0.550603  1.327892 -0.795514  1.330085   \n",
      "362396  1.328480 -0.608544  1.329517 -0.550603  1.327892 -0.795514  1.330085   \n",
      "362397  1.328480 -0.608544  1.329517 -0.550603  1.327892 -0.795514  1.330085   \n",
      "362398  1.328480 -0.668256  1.329517 -0.354503  1.327892 -0.795514  1.330085   \n",
      "362399  1.328480 -0.668256  1.329517 -0.354503  1.327892 -0.795514  1.330085   \n",
      "\n",
      "               7         8         9  ...       139       140  141  142  143  \\\n",
      "0      -0.425448  0.319404 -0.844157  ... -0.816832 -0.825238  0.0  0.0  0.0   \n",
      "1      -0.425448  0.320383 -0.854876  ...  0.464300  0.452887  0.0  0.0  0.0   \n",
      "2      -0.425448  0.317445 -0.762942  ... -0.798788 -0.807237  0.0  0.0  0.0   \n",
      "3      -0.425448  0.319404 -0.561348  ...  0.465974  0.454558  0.0  0.0  0.0   \n",
      "4      -0.425448  0.319404 -0.561348  ... -0.410306 -0.419666  0.0  0.0  0.0   \n",
      "...          ...       ...       ...  ...       ...       ...  ...  ...  ...   \n",
      "362395 -0.719126  1.328302 -0.870542  ... -0.697642 -0.706328  0.0  0.0  0.0   \n",
      "362396 -0.611748  1.328302 -0.870542  ...  0.460395  0.448992  0.0  0.0  0.0   \n",
      "362397 -0.611748  1.328302 -0.870542  ... -0.827738 -0.836118  0.0  0.0  0.0   \n",
      "362398 -0.611748  1.328302 -0.870542  ...  0.590491  0.578783  0.0  0.0  0.0   \n",
      "362399 -0.611748  1.329282 -0.870542  ...  0.718751  0.706741  0.0  0.0  0.0   \n",
      "\n",
      "        144  145  146  147  148  \n",
      "0       2.0  2.0  2.0  2.0  2.0  \n",
      "1       2.0  2.0  2.0  2.0  2.0  \n",
      "2       3.0  3.0  2.0  2.0  2.0  \n",
      "3       2.0  2.0  3.0  2.0  2.0  \n",
      "4       1.0  1.0  1.0  2.0  2.0  \n",
      "...     ...  ...  ...  ...  ...  \n",
      "362395  1.0  1.0  1.0  1.0  1.0  \n",
      "362396  2.0  2.0  1.0  1.0  1.0  \n",
      "362397  2.0  2.0  2.0  1.0  1.0  \n",
      "362398  2.0  2.0  2.0  1.0  1.0  \n",
      "362399  2.0  2.0  2.0  2.0  1.0  \n",
      "\n",
      "[362400 rows x 149 columns]\n"
     ]
    }
   ],
   "source": [
    "#Reading the dataset\n",
    "#Importing the csv file \n",
    "#Training set and Testing set separately\n",
    "tr_d = pd.read_csv('FI2010_train.csv', index_col=0)\n",
    "print(tr_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362400, 149)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_d.shape# dimension the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6  \\\n",
      "0      0.381815 -0.669628  0.380290 -0.453518  0.383410 -0.454568  0.380638   \n",
      "1      0.381815 -0.669628  0.382253 -0.567963  0.383410 -0.454568  0.380638   \n",
      "2      0.381815 -0.669628  0.379308 -0.440016  0.382431 -0.788626  0.375729   \n",
      "3      0.381815 -0.669628  0.380290 -0.567963  0.382431 -0.788626  0.380638   \n",
      "4      0.381815 -0.669628  0.378326 -0.549317  0.382431 -0.788626  0.378674   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "31932  1.462738 -0.030648  1.467926 -0.197623  1.462118 -0.401187  1.465580   \n",
      "31933  1.462738 -0.030648  1.467926 -0.197623  1.462118 -0.401187  1.465580   \n",
      "31934  1.462738 -0.030648  1.467926 -0.197623  1.462118 -0.401187  1.465580   \n",
      "31935  1.462738 -0.030648  1.467926 -0.197623  1.462118 -0.401187  1.466562   \n",
      "31936  1.462738 -0.030648  1.467926 -0.197623  1.462118 -0.401187  1.465580   \n",
      "\n",
      "              7         8         9  ...       139       140  141  142  143  \\\n",
      "0     -0.523162  0.384052 -0.870542  ...  2.770823  2.753998  0.0  0.0  0.0   \n",
      "1     -0.630002  0.384052 -0.870542  ...  1.685417  1.671139  0.0  0.0  0.0   \n",
      "2     -0.254717  0.382093 -0.630608  ...  3.039488  3.022033  0.0  0.0  0.0   \n",
      "3     -0.630002  0.382093 -0.630608  ...  3.469352  3.450888  0.0  0.0  0.0   \n",
      "4     -0.522625  0.382093 -0.630608  ...  3.684283  3.665316  0.0  0.0  0.0   \n",
      "...         ...       ...       ...  ...       ...       ...  ...  ...  ...   \n",
      "31932 -0.569871  1.461516 -0.004800  ...  1.624460  1.610326  0.0  0.0  0.0   \n",
      "31933 -0.623560  1.461516 -0.004800  ... -0.824794 -0.833181  0.0  0.0  0.0   \n",
      "31934 -0.677249  1.461516 -0.004800  ... -0.494134 -0.503298  0.0  0.0  0.0   \n",
      "31935 -0.737917  1.461516 -0.004800  ...  0.460724  0.449320  0.0  0.0  0.0   \n",
      "31936 -0.677249  1.461516 -0.004800  ... -0.571369 -0.580351  0.0  0.0  0.0   \n",
      "\n",
      "       144  145  146  147  148  \n",
      "0      2.0  2.0  2.0  2.0  2.0  \n",
      "1      2.0  2.0  2.0  2.0  2.0  \n",
      "2      3.0  3.0  2.0  2.0  2.0  \n",
      "3      1.0  1.0  3.0  2.0  2.0  \n",
      "4      3.0  3.0  1.0  2.0  2.0  \n",
      "...    ...  ...  ...  ...  ...  \n",
      "31932  2.0  2.0  2.0  2.0  2.0  \n",
      "31933  2.0  2.0  2.0  2.0  2.0  \n",
      "31934  2.0  2.0  2.0  2.0  2.0  \n",
      "31935  2.0  2.0  2.0  2.0  2.0  \n",
      "31936  2.0  2.0  2.0  2.0  2.0  \n",
      "\n",
      "[31937 rows x 149 columns]\n"
     ]
    }
   ],
   "source": [
    "#uploading test data\n",
    "te_d = pd.read_csv('FI2010_test.csv', index_col=0)\n",
    "print(te_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31937, 149)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_d.shape#dimension of test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Data Preprocessing :technique that involves transforming raw data into an understandable format. Real-world data is often incomplete, inconsistent, and/or lacking in certain behaviors or trends, and is likely to contain many errors. Data preprocessing is a proven method of resolving such issues.\n",
    "*Training of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ready data for training:\n",
    "# 1. sample_size=100: the most 100 recent updates\n",
    "# 2. feature_num=40: 40 features per time stamp\n",
    "# 3. target_num=5: relative changes for the next 1,2,3,5 and 10 events(5 in total)\n",
    "def data_generator(data, batch_size=32, lookback=100,\n",
    "                   feature_num=40, target_delay=1, shuffle=False):\n",
    "    data = data.values\n",
    "    shape = data.shape\n",
    "    max_index = shape[0]\n",
    "    min_index = 0\n",
    "    i = min_index + lookback\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(min_index + lookack, max_index)\n",
    "        else:\n",
    "            if i + batch_size >= max_index:\n",
    "                i = min_index + lookback\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "        samples = np.zeros((len(rows), lookback, feature_num))\n",
    "        targets = np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            samples[j] = data[row - lookback: row, 0: feature_num]  # take the first 40 columns as features\n",
    "            targets[j] = data[row - 1, target_delay - 6]\n",
    "        samples = samples.reshape(samples.shape[0], samples.shape[1],\n",
    "                                  samples.shape[2], 1)# add the 4th dimension: 1 channel\n",
    "        # \"Benchmark dataset for mid-price forecasting of limit order book data with machine learning\"\n",
    "        # labels 1: equal to or greater than 0.002\n",
    "        # labels 2: -0.00199 to 0.00199\n",
    "        # labels 3: smaller or equal to -0.002\n",
    "        # Y=Y-1 relabels as 0,1,2\n",
    "        targets = targets - 1\n",
    "        targets = targets.astype(int)\n",
    "        targets = to_categorical(targets, num_classes=3)# y is the next event's mid price (k=1)\n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 40, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 100, 20, 16)  48          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 100, 20, 16)  0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 100, 20, 16)  1040        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 100, 20, 16)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 100, 20, 16)  1040        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 100, 20, 16)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 100, 10, 16)  528         leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 100, 10, 16)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 100, 10, 16)  1040        leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 100, 10, 16)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 100, 10, 16)  1040        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 100, 10, 16)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 100, 1, 16)   2576        leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 100, 1, 16)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 100, 1, 16)   1040        leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 100, 1, 16)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 100, 1, 16)   1040        leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 100, 1, 16)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 100, 1, 32)   544         leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 100, 1, 32)   544         leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 100, 1, 32)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 100, 1, 32)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 100, 1, 16)   0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 100, 1, 32)   3104        leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 100, 1, 32)   5152        leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 100, 1, 32)   544         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 100, 1, 32)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 100, 1, 32)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 100, 1, 32)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 100, 1, 96)   0           leaky_re_lu_10[0][0]             \n",
      "                                                                 leaky_re_lu_12[0][0]             \n",
      "                                                                 leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 100, 96)      0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           41216       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            195         lstm[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 60,691\n",
      "Trainable params: 60,691\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# the size of a single input is (100,40)\n",
    "input_tensor = Input(shape=(100,40,1))\n",
    "\n",
    "# convolutional filter is (1,2) with stride of (1,2)\n",
    "layer_x = layers.Conv2D(16, (1,2), strides=(1,2))(input_tensor)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "\n",
    "layer_x = layers.Conv2D(16, (1,2), strides=(1,2))(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "\n",
    "layer_x = layers.Conv2D(16, (1,10))(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "layer_x = layers.Conv2D(16, (4,1), padding='same')(layer_x)\n",
    "layer_x = layers.LeakyReLU(alpha=0.01)(layer_x)\n",
    "\n",
    "# Inception Module\n",
    "tower_1 = layers.Conv2D(32, (1,1), padding='same')(layer_x)\n",
    "tower_1 = layers.LeakyReLU(alpha=0.01)(tower_1)\n",
    "tower_1 = layers.Conv2D(32, (3,1), padding='same')(tower_1)\n",
    "tower_1 = layers.LeakyReLU(alpha=0.01)(tower_1)\n",
    "\n",
    "tower_2 = layers.Conv2D(32, (1,1), padding='same')(layer_x)\n",
    "tower_2 = layers.LeakyReLU(alpha=0.01)(tower_2)\n",
    "tower_2 = layers.Conv2D(32, (5,1), padding='same')(tower_2)\n",
    "tower_2 = layers.LeakyReLU(alpha=0.01)(tower_2)  \n",
    "\n",
    "tower_3 = layers.MaxPooling2D((3,1), padding='same', strides=(1,1))(layer_x)\n",
    "tower_3 = layers.Conv2D(32, (1,1), padding='same')(tower_3)\n",
    "tower_3 = layers.LeakyReLU(alpha=0.01)(tower_3)\n",
    "\n",
    "layer_x = layers.concatenate([tower_1, tower_2, tower_3], axis=-1)\n",
    "\n",
    "# concatenate features of tower_1, tower_2, tower_3\n",
    "layer_x = layers.Reshape((100,96))(layer_x)\n",
    "\n",
    "# 64 LSTM units\n",
    "layer_x = LSTM(64)(layer_x)\n",
    "# The last output layer uses a softmax activation function\n",
    "output = layers.Dense(3, activation='softmax')(layer_x)\n",
    "model = Model(input_tensor, output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11325/11325 [==============================] - 9926s 876ms/step - loss: 0.8804 - accuracy: 0.6391\n",
      "Epoch 2/50\n",
      "11325/11325 [==============================] - 2157s 191ms/step - loss: 0.8156 - accuracy: 0.6467\n",
      "Epoch 3/50\n",
      "11325/11325 [==============================] - 2294s 203ms/step - loss: 0.6769 - accuracy: 0.7013\n",
      "Epoch 4/50\n",
      "11325/11325 [==============================] - 31447s 3s/step - loss: 0.6588 - accuracy: 0.7112\n",
      "Epoch 5/50\n",
      "11325/11325 [==============================] - 2773s 245ms/step - loss: 0.6164 - accuracy: 0.7541\n",
      "Epoch 6/50\n",
      "11325/11325 [==============================] - 2771s 245ms/step - loss: 0.5803 - accuracy: 0.7744\n",
      "Epoch 7/50\n",
      "11325/11325 [==============================] - 2608s 230ms/step - loss: 0.5722 - accuracy: 0.7781\n",
      "Epoch 8/50\n",
      "11325/11325 [==============================] - 2333s 206ms/step - loss: 0.5668 - accuracy: 0.7807\n",
      "Epoch 9/50\n",
      "11325/11325 [==============================] - 2234s 197ms/step - loss: 0.5614 - accuracy: 0.7828\n",
      "Epoch 10/50\n",
      "11325/11325 [==============================] - 3946s 348ms/step - loss: 0.5570 - accuracy: 0.7852\n",
      "Epoch 11/50\n",
      "11325/11325 [==============================] - 4140s 366ms/step - loss: 0.5531 - accuracy: 0.7872\n",
      "Epoch 12/50\n",
      "11325/11325 [==============================] - 2173s 192ms/step - loss: 0.5498 - accuracy: 0.7888\n",
      "Epoch 13/50\n",
      "11325/11325 [==============================] - 3390s 299ms/step - loss: 0.5470 - accuracy: 0.7902\n",
      "Epoch 14/50\n",
      "11325/11325 [==============================] - 2010s 177ms/step - loss: 0.5443 - accuracy: 0.7916\n",
      "Epoch 15/50\n",
      "11325/11325 [==============================] - 2049s 181ms/step - loss: 0.5420 - accuracy: 0.7927\n",
      "Epoch 16/50\n",
      "11325/11325 [==============================] - 5944s 525ms/step - loss: 0.5396 - accuracy: 0.7938\n",
      "Epoch 17/50\n",
      "11325/11325 [==============================] - 2075s 183ms/step - loss: 0.5377 - accuracy: 0.7944\n",
      "Epoch 18/50\n",
      "11325/11325 [==============================] - 1999s 176ms/step - loss: 0.5354 - accuracy: 0.7953\n",
      "Epoch 19/50\n",
      "11325/11325 [==============================] - 1955s 173ms/step - loss: 0.5333 - accuracy: 0.7962\n",
      "Epoch 20/50\n",
      "11325/11325 [==============================] - 1956s 173ms/step - loss: 0.5313 - accuracy: 0.7970\n",
      "Epoch 21/50\n",
      "11325/11325 [==============================] - 2937s 259ms/step - loss: 0.5295 - accuracy: 0.7979\n",
      "Epoch 22/50\n",
      "11325/11325 [==============================] - 1854s 164ms/step - loss: 0.5280 - accuracy: 0.7983\n",
      "Epoch 23/50\n",
      "11325/11325 [==============================] - 1845s 163ms/step - loss: 0.5265 - accuracy: 0.7988\n",
      "Epoch 24/50\n",
      "11325/11325 [==============================] - 1844s 163ms/step - loss: 0.5249 - accuracy: 0.7992\n",
      "Epoch 25/50\n",
      "11325/11325 [==============================] - 2057s 182ms/step - loss: 0.5232 - accuracy: 0.8000\n",
      "Epoch 26/50\n",
      "11325/11325 [==============================] - 1882s 166ms/step - loss: 0.5217 - accuracy: 0.8005\n",
      "Epoch 27/50\n",
      "11325/11325 [==============================] - 1884s 166ms/step - loss: 0.5204 - accuracy: 0.8008\n",
      "Epoch 28/50\n",
      "11325/11325 [==============================] - 2157s 190ms/step - loss: 0.5191 - accuracy: 0.8010\n",
      "Epoch 29/50\n",
      "11325/11325 [==============================] - 1907s 168ms/step - loss: 0.5179 - accuracy: 0.8017\n",
      "Epoch 30/50\n",
      "11325/11325 [==============================] - 1916s 169ms/step - loss: 0.5169 - accuracy: 0.8022\n",
      "Epoch 31/50\n",
      "11325/11325 [==============================] - 3869s 342ms/step - loss: 0.5159 - accuracy: 0.8025\n",
      "Epoch 32/50\n",
      "11325/11325 [==============================] - 3854s 340ms/step - loss: 0.5148 - accuracy: 0.8028\n",
      "Epoch 33/50\n",
      "11325/11325 [==============================] - 4783s 422ms/step - loss: 0.5139 - accuracy: 0.8030\n",
      "Epoch 34/50\n",
      "11325/11325 [==============================] - 2060s 182ms/step - loss: 0.5131 - accuracy: 0.8029\n",
      "Epoch 35/50\n",
      "11325/11325 [==============================] - 4586s 405ms/step - loss: 0.5122 - accuracy: 0.8035\n",
      "Epoch 36/50\n",
      "11325/11325 [==============================] - 1924s 170ms/step - loss: 0.5115 - accuracy: 0.8039\n",
      "Epoch 37/50\n",
      "11325/11325 [==============================] - 1936s 171ms/step - loss: 0.5104 - accuracy: 0.8041\n",
      "Epoch 38/50\n",
      "11325/11325 [==============================] - 1965s 173ms/step - loss: 0.5098 - accuracy: 0.8041\n",
      "Epoch 39/50\n",
      "11325/11325 [==============================] - 1989s 176ms/step - loss: 0.5091 - accuracy: 0.8044\n",
      "Epoch 40/50\n",
      "11325/11325 [==============================] - 1935s 171ms/step - loss: 0.5084 - accuracy: 0.8046\n",
      "Epoch 41/50\n",
      "11325/11325 [==============================] - 1944s 172ms/step - loss: 0.5078 - accuracy: 0.8049\n",
      "Epoch 42/50\n",
      "11325/11325 [==============================] - 1912s 169ms/step - loss: 0.5071 - accuracy: 0.8052\n",
      "Epoch 43/50\n",
      "11325/11325 [==============================] - 1911s 169ms/step - loss: 0.5063 - accuracy: 0.8057\n",
      "Epoch 44/50\n",
      "11325/11325 [==============================] - 1936s 171ms/step - loss: 0.5059 - accuracy: 0.8056\n",
      "Epoch 45/50\n",
      "11325/11325 [==============================] - 2222s 196ms/step - loss: 0.5049 - accuracy: 0.8060\n",
      "Epoch 46/50\n",
      "11325/11325 [==============================] - 2006s 177ms/step - loss: 0.5040 - accuracy: 0.8066\n",
      "Epoch 47/50\n",
      "11325/11325 [==============================] - 1931s 171ms/step - loss: 0.5036 - accuracy: 0.8067\n",
      "Epoch 48/50\n",
      "11325/11325 [==============================] - 1933s 171ms/step - loss: 0.5032 - accuracy: 0.8066\n",
      "Epoch 49/50\n",
      "11325/11325 [==============================] - 1935s 171ms/step - loss: 0.5027 - accuracy: 0.8071\n",
      "Epoch 50/50\n",
      "11325/11325 [==============================] - 1938s 171ms/step - loss: 0.5021 - accuracy: 0.8071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x145cc2c50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "steps_per_epoch =  len(train_data) // batch_size\n",
    "train_gen = data_generator(train_data, batch_size=batch_size, lookback=100,\n",
    "                   feature_num=40, target_delay=1, shuffle=False)\n",
    "opt = keras.optimizers.RMSprop(lr=0.01, epsilon=1)# learning rate and epsilon are the same as paper DeepLOB\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.fit_generator(train_gen,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
